# TEMPLATE
# <MODEL_NAME_YAML>:
#   model_name: <OPENROUTER_MODEL_NAME>
#   short_model_name: <SHORT_OFFICIAL_NAME>
#   endpoint:
#     api_base: https://openrouter.ai/api/v1
#     api_key: ${OPENROUTER_API_KEY}  # IS LOADED AT RUNTIME
#   pricing:
#     input: <PRICE_PER_MILLION_TOKENS>
#     output: <PRICE_PER_MILLION_TOKENS>
#   parameters:
#     max_tokens: <INT_MAX_NUM_TOKENS>
#     temperature: <FLOAT_BETWEEN_0_AND_1>
#     <MAYBE OTHER PARAMS>: ...

# SIMPLE FLOW (SINGLE MODEL APPROACH)
simple_flow:
  worker_model_1:
    model_name: meta-llama/llama-3.1-8b-instruct   # 8B | $0.02 in / $0.05 out
    short_model_name: Llama 3.1 8B
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.02
      output: 0.05
    parameters:
      max_tokens: 8192
      temperature: 0.5

  worker_model_2:
    model_name: mistralai/mistral-small-3.2-24b-instruct  # 24B
    short_model_name: Mistral Small 3.2 24B
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.06
      output: 0.18
    parameters:
      max_tokens: 8192
      temperature: 0.5

  worker_model_3:
    model_name: qwen/qwen3-32b        # 32B
    short_model_name: Qwen 3 32B
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.08
      output: 0.24
    parameters:
      max_tokens: 8192
      temperature: 0.5

  worker_model_4:
    model_name: meta-llama/llama-3.1-70b-instruct  # 70B
    short_model_name: Llama 3.1 70B
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.10
      output: 0.32
    parameters:
      max_tokens: 8192
      temperature: 0.5

  worker_model_5:
    model_name: deepseek/deepseek-chat-v3.1
    short_model_name: DeepSeek V3.1
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.15
      output: 0.75
    parameters:
      max_tokens: 8192
      temperature: 0.5


# CASCADE MODELS
cascade_complex_run:
  # CASCADE LEVEL 1 - 2 worker models
  cascade_lvl_1:
    worker_model_1:
      model_name: mistralai/mistral-small-3.2-24b-instruct  # 24 Bil. | 0.06 (input) | 0.18 (output)
      short_model_name: Mistral Small 3.2 24B (Leader)
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.02
        output: 0.05
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_2:
      # model_name: nvidia/nemotron-nano-9b-v2  # 9 Bil. | 0.04 (input) | 0.16 (output)
      model_name: meta-llama/llama-3.1-8b-instruct  # 8 Bil. | 0.02 (input) | 0.05 (output)
      short_model_name: Llama 3.1 8B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.017
        output: 0.11
      parameters:
        max_tokens: 8192
        temperature: 0.5

  # CASCADE LEVEL 2 - 3 worker models
  cascade_lvl_2:
    worker_model_1:
      model_name: deepseek/deepseek-v3.2 # 32 Bil. | 0.10 (input) | 0.30 (output)
      short_model_name: deepseek/deepseek-v3.2 32B (Leader)
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.05
        output: 0.22
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_2:
      model_name: mistralai/mistral-small-3.2-24b-instruct  # 24 Bil. | 0.06 (input) | 0.18 (output)
      short_model_name: Mistral Small 3.2 24B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.06
        output: 0.14
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_3:
      model_name: google/gemma-3-27b-it  # 27 Bil. | 0.04 (input) | 0.15 (output)
      short_model_name: Google Gemma 3 27B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.03
        output: 0.10
      parameters:
        max_tokens: 8192
        temperature: 0.5

  # CASCADE LEVEL 3 - 3 stronger worker models
  cascade_lvl_3:
    worker_model_1:
      model_name: meta-llama/llama-3.1-70b-instruct  # 70 Bil. | 0.10 (input) | 0.32 (output)
      short_model_name: Llama 3.1 70B (Leader)
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.03
        output: 0.14
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_2:
      model_name: qwen/qwen-2.5-32b-instruct  # 32 Bil. | 0.10 (input) | 0.30 (output)
      short_model_name: Qwen 2.5 32B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.04
        output: 0.15
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_3:
      model_name: deepseek/deepseek-v3.2  # 30 Bil. | 0.05 (input) | 0.20 (output)
      short_model_name: deepseek/deepseek-v3.2
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.06
        output: 0.18
      parameters:
        max_tokens: 8192
        temperature: 0.5

  # CASCADE LEVEL 4 - 4 worker models
  cascade_lvl_4:
    worker_model_1:
      model_name: deepseek/deepseek-chat-v3.1  # 671B MoE | 0.15 (input) | 0.75 (output)
      short_model_name: DeepSeek Chat V3.1 (Leader)
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.10
        output: 0.10
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_2:
      model_name: meta-llama/llama-3.1-70b-instruct  # 70 Bil. | 0.10 (input) | 0.32 (output)
      short_model_name: Llama 3.1 70B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.05
        output: 0.20
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_3:
      model_name: qwen/qwen-2.5-72b-instruct  # 72 Bil. | 0.35 (input) | 1.20 (output)
      short_model_name: Qwen 2.5 72B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.08
        output: 0.24
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_4:
      model_name: nousresearch/hermes-4-70b  # 70 Bil. | 0.11 (input) | 0.38 (output)
      short_model_name: Hermes 4 70B
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.05
        output: 0.20
      parameters:
        max_tokens: 8192
        temperature: 0.5

  # CASCADE LEVEL 5 - 5 worker models
  cascade_lvl_5:
    worker_model_1:
      model_name: minimax/minimax-m2.5  # 30 Bil. | 0.06 (input) | 0.40 (output)
      short_model_name: minimax/minimax-m2.5
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.06
        output: 0.40
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_2:
      model_name: openai/gpt-oss-120b  # 49 Bil. | 0.10 (input) | 0.40 (output)
      short_model_name: openai/gpt-oss-120b
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.10
        output: 0.40
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_3:
      model_name: qwen/qwen3-coder-next  # 70 Bil. | 0.11 (input) | 0.38 (output)
      short_model_name:  Qwen3 Coder Next
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.11
        output: 0.38
      parameters:
        max_tokens: 8192
        temperature: 0.5
    worker_model_4:
      model_name: deepseek/deepseek-chat-v3.1  # 671B MoE | 0.15 (input) | 0.75 (output)
      short_model_name: DeepSeek Chat V3.1 (Leader)
      endpoint:
        api_base_url: https://openrouter.ai/api/v1
        api_key: ${OPENROUTER_API_KEY}
      pricing:
        input: 0.05
        output: 0.40
      parameters:
        max_tokens: 8192
        temperature: 0.5

# JUDGE MODEL
judge_models:
  judge_model_1:
    model_name: openai/gpt-oss-120b:exacto  # 117 Bil. | 0.039 (input) | 0.19 (output)
    short_model_name: OpenAI GPT OSS 120B Exacto
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.039
      output: 0.19
    parameters:
      max_tokens: 8192
      temperature: 0.5
  judge_model_2:
    model_name: google/gemini-2.5-flash-lite-preview-09-2025  # <50 Bil. | 0.10 (input) | 0.40 (output)
    short_model_name: Google Gemini 2.5 Flash Lite Preview 09-2025
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.10
      output: 0.40
    parameters:
      max_tokens: 8192
      temperature: 0.5
  judge_model_3:
    model_name: openai/gpt-4.1-nano  # <40 Bil. | 0.10 (input) | 0.40 (output)
    short_model_name: OpenAI GPT 4.1 Nano
    endpoint:
      api_base_url: https://openrouter.ai/api/v1
      api_key: ${OPENROUTER_API_KEY}
    pricing:
      input: 0.10
      output: 0.40
    parameters:
      max_tokens: 8192
      temperature: 0.5